{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMURGc0cBgZhwHvo37C4sdg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/chess_website/blob/models_init/models/Chess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Lichess Puzzles"
      ],
      "metadata": {
        "id": "K3OqkOzIZD9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zstandard"
      ],
      "metadata": {
        "id": "9D9F_QsRLrMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zstandard\n",
        "import csv\n",
        "import io\n",
        "\n",
        "url = \"https://database.lichess.org/lichess_db_puzzle.csv.zst\"\n",
        "compressed_file_path = \"lichess_db_puzzle.csv.zst\"\n",
        "output_csv_path = \"lichess_db_puzzle.csv\"\n",
        "\n",
        "# Download the Zstandard compressed file\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    with open(compressed_file_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"File downloaded successfully to {compressed_file_path}\")\n",
        "else:\n",
        "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "\n",
        "# Extract the Zstandard compressed file to CSV\n",
        "with open(compressed_file_path, 'rb') as compressed_file:\n",
        "    dctx = zstandard.ZstdDecompressor()\n",
        "    with dctx.stream_reader(compressed_file) as reader:\n",
        "        with io.TextIOWrapper(reader, encoding='utf-8') as text_reader:\n",
        "            with open(output_csv_path, 'w', newline='', encoding='utf-8') as output_csv:\n",
        "                writer = csv.writer(output_csv)\n",
        "\n",
        "                for line in text_reader:\n",
        "                    decoded_line = line.strip()\n",
        "                    csv_row = decoded_line.split(',')\n",
        "                    writer.writerow(csv_row)\n",
        "\n",
        "print(f\"File extracted successfully to {output_csv_path}\")\n"
      ],
      "metadata": {
        "id": "LzbeuaIO7hqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Puzzle Data"
      ],
      "metadata": {
        "id": "gkL6B0oeZNvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "csv_file_path = \"lichess_db_puzzle.csv\"\n",
        "\n",
        "# Use read_csv to load the data into a DataFrame\n",
        "df = pd.read_csv(csv_file_path, sep=\",\")\n",
        "\n",
        "# df_description = df.describe()\n",
        "\n",
        "# # Print the summary\n",
        "# print(df_description)"
      ],
      "metadata": {
        "id": "byMVyr9sY7ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore Data"
      ],
      "metadata": {
        "id": "yTHWtFITdpV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame to verify the data has been loaded\n",
        "pd.set_option('display.max_rows', None)\n",
        "print(df.dtypes)\n",
        "df.head(100)"
      ],
      "metadata": {
        "id": "KapDonfEZaGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "MXwqbgiT00kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "DmAYHrqD0nqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.iloc[84]['FEN'])\n",
        "print(df.iloc[84]['Moves'])"
      ],
      "metadata": {
        "id": "l96wIdcL0KiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the FEN and moves columns\n",
        "selected_columns = [\"FEN\", \"Moves\"]\n",
        "df_subset = df[selected_columns]"
      ],
      "metadata": {
        "id": "rk2UUwIOdHCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.head()"
      ],
      "metadata": {
        "id": "2Deb1daxdbJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.iloc[84]"
      ],
      "metadata": {
        "id": "MeG2tH3Bz1je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-chess"
      ],
      "metadata": {
        "id": "1D-FVCAsmvyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_to_index(move):\n",
        "    \"\"\"\n",
        "    Convert chess move (e.g., \"e2e4\") to index number based on the specified mapping.\n",
        "    \"\"\"\n",
        "    file_mapping = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7}\n",
        "    rank_mapping = {str(i+1): i * 8 for i in range(8)}\n",
        "\n",
        "    start_square = move[:2]\n",
        "    end_square = move[2:4]\n",
        "\n",
        "    start_index = file_mapping[start_square[0]] + rank_mapping[start_square[1]]\n",
        "    end_index = file_mapping[end_square[0]] + rank_mapping[end_square[1]]\n",
        "\n",
        "    return start_index, end_index\n",
        "\n",
        "\n",
        "move_to_index(\"e2e4\")"
      ],
      "metadata": {
        "id": "Otrrn4LusdJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chess_move_one_hot_encoding(chess_move):\n",
        "    # Create an empty dictionary to map squares to column names\n",
        "    square_columns = {}\n",
        "    columns = []\n",
        "\n",
        "    # Define the columns based on chess board squares\n",
        "    for file in 'abcdefgh':\n",
        "        for rank in '12345678':\n",
        "            square = file + rank\n",
        "            from_col_name = 'from_' + square\n",
        "            to_col_name = 'to_' + square\n",
        "            columns.extend([from_col_name, to_col_name])\n",
        "            square_columns[square] = (from_col_name, to_col_name)\n",
        "\n",
        "    # Initialize a dictionary to store the one-hot encoded values\n",
        "    encoding = {col: 0 for col in columns}\n",
        "\n",
        "    # Extract the \"from\" and \"to\" squares from the chess move\n",
        "    from_square = chess_move[:2]\n",
        "    to_square = chess_move[2:4]\n",
        "\n",
        "    # Update the corresponding columns to 1\n",
        "    encoding[square_columns[from_square][0]] = 1\n",
        "    encoding[square_columns[to_square][1]] = 1\n",
        "\n",
        "    return encoding\n",
        "\n",
        "# Example usage:\n",
        "chess_move = \"e2e4\"\n",
        "one_hot_encoding = chess_move_one_hot_encoding(chess_move)\n",
        "print(one_hot_encoding)\n",
        "print(list(one_hot_encoding.values()))\n"
      ],
      "metadata": {
        "id": "PpR7hWKrmESh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in df_subset.head(1).iterrows():\n",
        "    # Get the FEN string from the current row\n",
        "    fen_string = row[\"FEN\"]\n",
        "\n",
        "    # Create a chess.Board object from the FEN string\n",
        "    board = chess.Board(fen_string)\n",
        "\n",
        "    for move in row[\"Moves\"].split(\" \"):\n",
        "      # Print the board state and moves\n",
        "      print(move, \"\\n\")\n",
        "      print(f\"Board state for puzzle {index + 1} (FEN: {board.board_fen()}):\")\n",
        "      print(board)\n",
        "      print(\"Moves:\", row[\"Moves\"])\n",
        "      print(\"\\n\" + \"=\" * 30 + \"\\n\")\n",
        "      # Extract and print the piece at each square\n",
        "      i=0\n",
        "      for square in chess.SQUARES:\n",
        "          piece = board.piece_at(square)\n",
        "          print(f\"{i} - Square {chess.square_name(square)}: {piece}\")\n",
        "          i+=1\n",
        "      print(move_to_index(move))\n",
        "      m = chess.Move.from_uci(move)\n",
        "      board.push(m)  # Make the move\n",
        "      break\n"
      ],
      "metadata": {
        "id": "DB4Z4BYbdf-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board"
      ],
      "metadata": {
        "id": "CZIn1qBzDZaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(board.piece_at(15)))\n",
        "print(board.piece_at(15).piece_type)\n",
        "print(board.piece_at(22).color)\n",
        "print(board.piece_at(22).symbol())"
      ],
      "metadata": {
        "id": "zy8e3rmiDVTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(board.piece_at(44).__str__())\n",
        "print(board.piece_at(0).__str__())"
      ],
      "metadata": {
        "id": "28ulIuQLEQRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "Wf9deOPVvyRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_count = 30000\n",
        "sampled_df = df_subset.sample(n=sample_count, random_state=42)"
      ],
      "metadata": {
        "id": "iPGeldke_2hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store row data\n",
        "rows_data = []\n",
        "\n",
        "i=0\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in sampled_df.iterrows():\n",
        "    # Get the FEN string from the current row\n",
        "    fen_string = row[\"FEN\"]\n",
        "\n",
        "    # Create a chess.Board object from the FEN string\n",
        "    try:\n",
        "        board = chess.Board(fen_string)\n",
        "    except:\n",
        "        print(\"An exception occurred\")\n",
        "        continue\n",
        "\n",
        "    # Not Good moves\n",
        "    nextMove = row[\"Moves\"].split(\" \")[0]\n",
        "    if board.legal_moves.count() > 2:\n",
        "      for move in list(board.legal_moves)[:2]:\n",
        "          # Extract the piece at each square and append to row_data\n",
        "          move = move.uci()\n",
        "          if nextMove != move:\n",
        "            row_data = [board.piece_at(square).__str__() for square in chess.SQUARES]\n",
        "\n",
        "            # Append the move index to row_data\n",
        "            row_data.extend(chess_move_one_hot_encoding(move).values())\n",
        "            # not good move\n",
        "            row_data.extend(list([0]))\n",
        "            # Append the row_data to the list\n",
        "            rows_data.append(row_data)\n",
        "\n",
        "    # Good moves\n",
        "    for move in row[\"Moves\"].split(\" \"):\n",
        "        # Extract the piece at each square and append to row_data\n",
        "        row_data = [board.piece_at(square).__str__() for square in chess.SQUARES]\n",
        "\n",
        "        # Append the move index to row_data\n",
        "        row_data.extend(chess_move_one_hot_encoding(move).values())\n",
        "        # good move\n",
        "        row_data.extend(list([1]))\n",
        "        # Make the move on the board\n",
        "        m = chess.Move.from_uci(move)\n",
        "        board.push(m)\n",
        "        # Append the row_data to the list\n",
        "        rows_data.append(row_data)\n",
        "    i+=1\n",
        "    if i % 5000 == 0:\n",
        "      print(f\"{i} of {sample_count}\")\n",
        "\n",
        "# Create the result DataFrame in a single step\n",
        "columns = [f\"Square_{i}\" for i in range(64)] + list(chess_move_one_hot_encoding(\"a2a4\").keys()) + list([\"good_move\"])\n",
        "print(columns)\n",
        "result_df = pd.DataFrame(rows_data, columns=columns)"
      ],
      "metadata": {
        "id": "gRVcjaFfBVZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "move"
      ],
      "metadata": {
        "id": "9XIPMCfdt5fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.head(4)"
      ],
      "metadata": {
        "id": "fOK6kJ1-9HoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df.head(1)"
      ],
      "metadata": {
        "id": "k9ioCVV8qBDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.dtypes"
      ],
      "metadata": {
        "id": "jksOGrC9v70_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model"
      ],
      "metadata": {
        "id": "8XGOyvRN98S0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch pandas scikit-learn"
      ],
      "metadata": {
        "id": "VYnK7Bqpx3yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "temp_df = result_df\n",
        "# Replace 'Square_' columns with numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "for column in temp_df.columns:\n",
        "    if column.startswith('Square_'):\n",
        "        temp_df[column] = label_encoder.fit_transform(temp_df[column])\n",
        "\n",
        "# Convert 'good_move' column to tensor\n",
        "labels = torch.tensor(temp_df['good_move'].values, dtype=torch.float32)\n",
        "\n",
        "# Drop unnecessary columns (e.g., 'good_move') for input features\n",
        "features = temp_df.drop(columns=['good_move'])\n",
        "\n",
        "# Convert the remaining DataFrame to tensor\n",
        "features = torch.tensor(features.values, dtype=torch.float32)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the PyTorch dataset\n",
        "class ChessDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "# Create DataLoader instances\n",
        "train_dataset = ChessDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "val_dataset = ChessDataset(X_val, y_val)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define a simple neural network model\n",
        "class ChessModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ChessModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and move it to GPU if available\n",
        "model = ChessModel(input_size=features.size(1))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs.squeeze(), labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {val_loss/len(val_loader)}, Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "OvLJ7rm1yd_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T1OeDNbcziyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}