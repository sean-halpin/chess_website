{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6XqOhAzM0pZxzQXahN5zi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sean-halpin/chess_website/blob/models_init/models/Chess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Lichess Puzzles"
      ],
      "metadata": {
        "id": "K3OqkOzIZD9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zstandard"
      ],
      "metadata": {
        "id": "9D9F_QsRLrMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zstandard\n",
        "import csv\n",
        "import io\n",
        "\n",
        "url = \"https://database.lichess.org/lichess_db_puzzle.csv.zst\"\n",
        "compressed_file_path = \"lichess_db_puzzle.csv.zst\"\n",
        "output_csv_path = \"lichess_db_puzzle.csv\"\n",
        "\n",
        "# Download the Zstandard compressed file\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    with open(compressed_file_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"File downloaded successfully to {compressed_file_path}\")\n",
        "else:\n",
        "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
        "\n",
        "# Extract the Zstandard compressed file to CSV\n",
        "with open(compressed_file_path, 'rb') as compressed_file:\n",
        "    dctx = zstandard.ZstdDecompressor()\n",
        "    with dctx.stream_reader(compressed_file) as reader:\n",
        "        with io.TextIOWrapper(reader, encoding='utf-8') as text_reader:\n",
        "            with open(output_csv_path, 'w', newline='', encoding='utf-8') as output_csv:\n",
        "                writer = csv.writer(output_csv)\n",
        "\n",
        "                for line in text_reader:\n",
        "                    decoded_line = line.strip()\n",
        "                    csv_row = decoded_line.split(',')\n",
        "                    writer.writerow(csv_row)\n",
        "\n",
        "print(f\"File extracted successfully to {output_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzbeuaIO7hqX",
        "outputId": "6905d8ff-da52-47f9-9a03-e3c1f8a72ea7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully to lichess_db_puzzle.csv.zst\n",
            "File extracted successfully to lichess_db_puzzle.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Puzzle Data"
      ],
      "metadata": {
        "id": "gkL6B0oeZNvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "csv_file_path = \"lichess_db_puzzle.csv\"\n",
        "\n",
        "# Use read_csv to load the data into a DataFrame\n",
        "df = pd.read_csv(csv_file_path, sep=\",\")\n",
        "\n",
        "# df_description = df.describe()\n",
        "\n",
        "# # Print the summary\n",
        "# print(df_description)"
      ],
      "metadata": {
        "id": "byMVyr9sY7ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore Data"
      ],
      "metadata": {
        "id": "yTHWtFITdpV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame to verify the data has been loaded\n",
        "pd.set_option('display.max_rows', None)\n",
        "print(df.dtypes)\n",
        "df.head(100)"
      ],
      "metadata": {
        "id": "KapDonfEZaGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "MXwqbgiT00kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "DmAYHrqD0nqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.iloc[84]['FEN'])\n",
        "print(df.iloc[84]['Moves'])"
      ],
      "metadata": {
        "id": "l96wIdcL0KiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the FEN and moves columns\n",
        "selected_columns = [\"FEN\", \"Moves\"]\n",
        "df_subset = df[selected_columns]"
      ],
      "metadata": {
        "id": "rk2UUwIOdHCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.head()"
      ],
      "metadata": {
        "id": "2Deb1daxdbJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset.iloc[84]"
      ],
      "metadata": {
        "id": "MeG2tH3Bz1je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-chess"
      ],
      "metadata": {
        "id": "1D-FVCAsmvyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_to_index(move):\n",
        "    \"\"\"\n",
        "    Convert chess move (e.g., \"e2e4\") to index number based on the specified mapping.\n",
        "    \"\"\"\n",
        "    file_mapping = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7}\n",
        "    rank_mapping = {str(i+1): i * 8 for i in range(8)}\n",
        "\n",
        "    start_square = move[:2]\n",
        "    end_square = move[2:]\n",
        "\n",
        "    start_index = file_mapping[start_square[0]] + rank_mapping[start_square[1]]\n",
        "    end_index = file_mapping[end_square[0]] + rank_mapping[end_square[1]]\n",
        "\n",
        "    return start_index, end_index"
      ],
      "metadata": {
        "id": "Otrrn4LusdJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chess\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in df_subset.head(1).iterrows():\n",
        "    # Get the FEN string from the current row\n",
        "    fen_string = row[\"FEN\"]\n",
        "\n",
        "    # Create a chess.Board object from the FEN string\n",
        "    board = chess.Board(fen_string)\n",
        "\n",
        "    for move in row[\"Moves\"].split(\" \"):\n",
        "      # Print the board state and moves\n",
        "      print(move, \"\\n\")\n",
        "      print(f\"Board state for puzzle {index + 1} (FEN: {board.board_fen()}):\")\n",
        "      print(board)\n",
        "      print(\"Moves:\", row[\"Moves\"])\n",
        "      print(\"\\n\" + \"=\" * 30 + \"\\n\")\n",
        "      # Extract and print the piece at each square\n",
        "      i=0\n",
        "      for square in chess.SQUARES:\n",
        "          piece = board.piece_at(square)\n",
        "          print(f\"{i} - Square {chess.square_name(square)}: {piece}\")\n",
        "          i+=1\n",
        "      print(move_to_index(move))\n",
        "      m = chess.Move.from_uci(move)\n",
        "      board.push(m)  # Make the move\n",
        "      break\n"
      ],
      "metadata": {
        "id": "DB4Z4BYbdf-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board"
      ],
      "metadata": {
        "id": "CZIn1qBzDZaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(board.piece_at(15)))\n",
        "print(board.piece_at(15).piece_type)\n",
        "print(board.piece_at(22).color)\n",
        "print(board.piece_at(22).symbol())"
      ],
      "metadata": {
        "id": "zy8e3rmiDVTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(board.piece_at(44).__str__())\n",
        "print(board.piece_at(0).__str__())"
      ],
      "metadata": {
        "id": "28ulIuQLEQRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "Wf9deOPVvyRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_count = 50000\n",
        "sampled_df = df_subset.sample(n=50000, random_state=42)"
      ],
      "metadata": {
        "id": "iPGeldke_2hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to store row data\n",
        "rows_data = []\n",
        "\n",
        "i=0\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in sampled_df.iterrows():\n",
        "    # Get the FEN string from the current row\n",
        "    fen_string = row[\"FEN\"]\n",
        "\n",
        "    # Create a chess.Board object from the FEN string\n",
        "    try:\n",
        "        board = chess.Board(fen_string)\n",
        "    except:\n",
        "        print(\"An exception occurred\")\n",
        "        continue\n",
        "\n",
        "    for move in row[\"Moves\"].split(\" \"):\n",
        "        try:\n",
        "            move_src, move_dest = move_to_index(move)\n",
        "        except:\n",
        "            print(move, fen_string, \"\\n\", index, \"\\n\", row)\n",
        "            continue\n",
        "\n",
        "        # Extract the piece at each square and append to row_data\n",
        "        row_data = [board.piece_at(square).__str__() for square in chess.SQUARES]\n",
        "\n",
        "        # Append the move index to row_data\n",
        "        row_data.extend([move_src, move_dest])\n",
        "\n",
        "        # Make the move on the board\n",
        "        m = chess.Move.from_uci(move)\n",
        "        board.push(m)\n",
        "\n",
        "        # Append the row_data to the list\n",
        "        rows_data.append(row_data)\n",
        "    i+=1\n",
        "    if i % 5000 == 0:\n",
        "      print(f\"{i} of {sample_count}\")\n",
        "\n",
        "# Create the result DataFrame in a single step\n",
        "columns = [f\"Square_{i}\" for i in range(64)] + [\"move_src\", \"move_dest\"]\n",
        "result_df = pd.DataFrame(rows_data, columns=columns)"
      ],
      "metadata": {
        "id": "gRVcjaFfBVZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.head(2)"
      ],
      "metadata": {
        "id": "jksOGrC9v70_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Model"
      ],
      "metadata": {
        "id": "8XGOyvRN98S0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch pandas scikit-learn"
      ],
      "metadata": {
        "id": "VYnK7Bqpx3yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming your DataFrame is named 'df'\n",
        "# Extracting X and Y\n",
        "X = result_df.iloc[:, :64].values\n",
        "Y = result_df.iloc[:, 64:].values\n",
        "\n",
        "# Convert 'None', 'Pawn', 'Rook', 'Knight', 'Bishop', 'Queen', 'King' to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "X_encoded = label_encoder.fit_transform(X.flatten()).reshape(X.shape)\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_tensor = torch.tensor(X_encoded, dtype=torch.float32)\n",
        "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_tensor, Y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a simple CNN model for classification\n",
        "class ChessCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChessCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 16, 128)\n",
        "        self.fc2 = nn.Linear(128, 7)  # Adjust the number of output units to match the number of classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, 64)  # Reshape input for 1D convolution\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = ChessCNN()\n",
        "criterion = nn.CrossEntropyLoss()  # Change the loss function to CrossEntropyLoss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the model\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = data.TensorDataset(X_train, Y_train.long())  # Note: Use .long() for the labels\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, Y_test.long())  # Note: Use .long() for the labels\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'chess_cnn_model.pth')\n"
      ],
      "metadata": {
        "id": "9JNomSC5IwN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_outputs = model(X_test)\n",
        "    test_loss = criterion(test_outputs, Y_test)\n",
        "\n",
        "    # Count correct predictions\n",
        "    for i in range(len(Y_test)):\n",
        "        predicted_labels = test_outputs[i].numpy()\n",
        "        true_labels = Y_test[i].numpy()\n",
        "        if i == 1:\n",
        "          print(predicted_labels, true_labels)\n",
        "        if (predicted_labels == true_labels).all():\n",
        "            correct_predictions += 1\n",
        "\n",
        "print(f'Test Loss: {test_loss.item():.4f}')\n",
        "print(f'Number of correct predictions: {correct_predictions}/{len(Y_test)}')\n"
      ],
      "metadata": {
        "id": "p4jvBnVG_f9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ioojj6YOH2LM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}